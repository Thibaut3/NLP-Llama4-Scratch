{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la reproductibilité\n",
    "torch.manual_seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Globale ---\n",
    "class Config:\n",
    "    \n",
    "    # Architecture\n",
    "    d_model: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    block_size: int = 512\n",
    "    rms_norm_eps: float = 1e-5\n",
    "    rope_theta: float = 10000.0\n",
    "    vocab_size: int = None # Sera défini après le chargement des données\n",
    "\n",
    "    # MoE\n",
    "    num_local_experts: int = 4\n",
    "    num_experts_per_tok: int = 2\n",
    "    intermediate_size_expert_factor: int = 2 # Multiplicateur pour d_model\n",
    "    intermediate_size_shared_factor: int = 2 # Multiplicateur pour d_model\n",
    "\n",
    "    # Entraînement\n",
    "    learning_rate: float = 5e-4\n",
    "    batch_size: int = 2\n",
    "    epochs: int = 12000\n",
    "    eval_interval: int = 300\n",
    "\n",
    "    # Dérivé / Calculé\n",
    "    d_k: int = d_model // n_heads\n",
    "    intermediate_size_expert: int = d_model * intermediate_size_expert_factor\n",
    "    intermediate_size_shared: int = d_model * intermediate_size_shared_factor\n",
    "\n",
    "    # Device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Vérifications post-initialisation.\"\"\"\n",
    "        assert self.d_model % self.n_heads == 0, \"d_model doit être divisible par n_heads\"\n",
    "        self.d_k = self.d_model // self.n_heads\n",
    "        self.intermediate_size_expert = self.d_model * self.intermediate_size_expert_factor\n",
    "        self.intermediate_size_shared = self.d_model * self.intermediate_size_shared_factor\n",
    "\n",
    "    def print_config(self):\n",
    "        \"\"\"Affiche la configuration.\"\"\"\n",
    "        print(\"--- Configuration du Modèle ---\")\n",
    "        for key, value in self.__dict__.items():\n",
    "             # N'affiche pas les méthodes ou les attributs privés/spéciaux\n",
    "            if not key.startswith('_') and not callable(value):\n",
    "                print(f\"{key}: {value}\")\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "# Instancier la configuration\n",
    "config = Config()\n",
    "# Initialiser les valeurs calculées\n",
    "config.__post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tokenizer ---\n",
    "class SimpleCharTokenizer:\n",
    "    def __init__(self, corpus):\n",
    "        self.chars = sorted(list(set(corpus)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.char_to_int = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.int_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        print(f\"Tokenizer créé avec une taille de vocabulaire de: {self.vocab_size}\")\n",
    "        # print(f\"Vocabulaire: {''.join(self.chars)}\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.char_to_int[ch] for ch in text if ch in self.char_to_int]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return ''.join([self.int_to_char.get(id_val, '[UNK]') for id_val in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonctions Utilitaires ---\n",
    "def load_and_prepare_data(config):\n",
    "    print(\"Chargement des données...\")\n",
    "\n",
    "    # Charger le dataset Wikitext en français\n",
    "    wikitext_fr = load_dataset(\"asi/wikitext_fr\", split=\"train\", trust_remote_code=True)\n",
    "    corpus_raw_vocab = ' '.join(wikitext_fr['paragraph'])\n",
    "    print(f\"Corpus brut chargé (longueur: {len(corpus_raw_vocab)} caractères).\")\n",
    "\n",
    "    # Créer le tokenizer\n",
    "    tokenizer = SimpleCharTokenizer(corpus_raw_vocab)\n",
    "    config.vocab_size = tokenizer.vocab_size # Mettre à jour la config\n",
    "    \n",
    "    wikitext_fr = load_dataset(\"asi/wikitext_fr\", split=\"train\", trust_remote_code=True)\n",
    "    dataset  = wikitext_fr['paragraph'][:5000] # réduire la taille pour l'entrainement\n",
    "\n",
    "    block_size = config.block_size\n",
    "\n",
    "    # Créer les séquences d'entraînement x et y\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    all_attention_masks = []\n",
    "\n",
    "    for idx, item in enumerate(dataset):\n",
    "        paragraph = item\n",
    "\n",
    "        paragraph = unicodedata.normalize('NFD', paragraph).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "        encoded_sequence = tokenizer.encode(paragraph)\n",
    "        num_tokens = len(encoded_sequence)\n",
    "\n",
    "        if num_tokens > block_size:\n",
    "            # Créer des séquences chevauchantes\n",
    "            for i in range(num_tokens - block_size):\n",
    "                x_chunk = encoded_sequence[i : i + block_size]\n",
    "                y_chunk = encoded_sequence[i + 1 : i + block_size + 1]\n",
    "                attention_mask = [1] * block_size  # Masque d'attention : 1 pour les tokens réels\n",
    "                all_x.append(x_chunk)\n",
    "                all_y.append(y_chunk)\n",
    "                all_attention_masks.append(attention_mask)\n",
    "        elif num_tokens <= block_size:\n",
    "            # Ajouter du padding si la séquence est trop courte\n",
    "            padding_length = block_size - num_tokens\n",
    "            x_padded = encoded_sequence + [0] * padding_length  # Pad à droite avec des zéros\n",
    "            y_padded = encoded_sequence[1:] + [0] * (padding_length + 1) # decalage de 1 et padding\n",
    "            x_padded = x_padded[:block_size]\n",
    "            y_padded = y_padded[:block_size]\n",
    "            attention_mask = [1] * num_tokens + [0] * padding_length  # 1 pour les tokens réels, 0 pour le padding\n",
    "            all_x.append(x_padded)\n",
    "            all_y.append(y_padded)\n",
    "            all_attention_masks.append(attention_mask)\n",
    "\n",
    "    if not all_x:\n",
    "        raise ValueError(\"Aucune séquence d'entraînement n'a pu être créée. Vérifiez la taille du corpus et la taille de bloc.\")\n",
    "    \n",
    "    train_x = torch.tensor(all_x, dtype=torch.long)\n",
    "    train_y = torch.tensor(all_y, dtype=torch.long)\n",
    "    attention_mask = torch.tensor(all_attention_masks, dtype=torch.long)\n",
    "    \n",
    "    num_sequences_available = train_x.shape[0]\n",
    "    print(f\"{num_sequences_available} paires de séquences input/target créées.\")\n",
    "    print(f\"Shape de train_x: {train_x.shape}\")\n",
    "    print(f\"Shape de train_y: {train_y.shape}\")\n",
    "    print(f\"Shape de attention_mask: {attention_mask.shape}\") #afficher la shape du mask\n",
    "\n",
    "    # Ajuster la taille du batch si nécessaire\n",
    "    if num_sequences_available < config.batch_size:\n",
    "        print(f\"Attention : Nombre de séquences ({num_sequences_available}) inférieur à la taille du batch ({config.batch_size}). Ajustement de la taille du batch.\")\n",
    "        config.batch_size = num_sequences_available\n",
    "        \n",
    "    return train_x, train_y, attention_mask, tokenizer\n",
    "\n",
    "def get_batch(data_x, data_y, attention_mask, batch_size, device):\n",
    "    num_sequences = data_x.shape[0]\n",
    "    indices = torch.randint(0, num_sequences, (batch_size,))\n",
    "    xb = data_x[indices].to(device)\n",
    "    yb = data_y[indices].to(device)\n",
    "    attention_mask_batch = attention_mask[indices].to(device) # Récupérer aussi le masque d'attention pour le batch\n",
    "    return xb, yb, attention_mask_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Composants du Modèle ---\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # Le gain (gamma) est un paramètre apprenable\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        # x: (..., dim)\n",
    "        # rsqrt: 1 / sqrt(x)\n",
    "        # + eps pour la stabilité numérique\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applique la normalisation puis multiplie par le gain apprenable\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, seq_len: int, theta: float = 10000.0, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.seq_len = seq_len\n",
    "        self.theta = theta\n",
    "        self.device = device\n",
    "        self.freqs_cis = self.precompute_freqs_cis(dim, seq_len, theta).to(device)\n",
    "\n",
    "    def precompute_freqs_cis(self, dim: int, end: int, theta: float = 10000.0):\n",
    "        # Calcule les fréquences inverses: 1.0 / (theta ** (2k / dim)) pour k = 0, 1, ..., dim/2 - 1\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2, dtype=torch.float)[: (dim // 2)] / dim))\n",
    "        # Crée les positions de 0 à end-1\n",
    "        t = torch.arange(end, dtype=torch.float)\n",
    "        # Calcule les angles: position * fréquence_inverse\n",
    "        freqs = torch.outer(t, freqs) # Shape (end, dim / 2)\n",
    "        # Convertit en nombres complexes: cos(angle) + i*sin(angle)\n",
    "        freqs_cis = torch.polar(torch.ones_like(freqs), freqs) # Shape (end, dim / 2)\n",
    "        return freqs_cis\n",
    "\n",
    "    def apply_rotary_emb(self, x: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "        # x: (B, T, H, Dk) ou (B, H, T, Dk) - on suppose (..., T, D) où D=dim\n",
    "        # freqs_cis: (T, Dk/2)\n",
    "        # Sépare x en parties réelles et imaginaires virtuelles\n",
    "        # x_ -> (..., T, Dk/2, 2)\n",
    "        x_ = x.float().reshape(*x.shape[:-1], -1, 2)\n",
    "        # Convertit en complexe: (..., T, Dk/2)\n",
    "        x_complex = torch.view_as_complex(x_)\n",
    "        # Adapte freqs_cis pour le broadcasting: (1, T, 1, Dk/2) ou (T, Dk/2) -> (1, T, 1, Dk/2)\n",
    "        # On suppose que freqs_cis est déjà (T, Dk/2)\n",
    "        freqs_cis = freqs_cis.unsqueeze(0).unsqueeze(2) # (1, T, 1, Dk/2)\n",
    "        # Applique la rotation complexe: x * exp(i*theta)\n",
    "        x_rotated = x_complex * freqs_cis # Broadcasting s'applique\n",
    "        # Reconvertit en réel: (..., T, Dk/2, 2)\n",
    "        x_out_real = torch.view_as_real(x_rotated)\n",
    "        # Recombine: (..., T, Dk)\n",
    "        x_out = x_out_real.flatten(3)\n",
    "        return x_out.type_as(x)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor):\n",
    "        # q, k: (B, T, H, Dk) ou (B, H, T, Dk) - on suppose (B, T, H, Dk)\n",
    "        seq_len = q.shape[1] # T\n",
    "        # Récupère les freqs précalculées pour la longueur de séquence actuelle\n",
    "        current_freqs_cis = self.freqs_cis[:seq_len].to(q.device) # (T, Dk/2)\n",
    "        # Applique RoPE\n",
    "        q_out = self.apply_rotary_emb(q, current_freqs_cis)\n",
    "        k_out = self.apply_rotary_emb(k, current_freqs_cis)\n",
    "        return q_out, k_out\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.n_heads = config.n_heads\n",
    "        self.d_model = config.d_model\n",
    "        self.d_k = config.d_k\n",
    "        self.head_dim = self.d_k # Alias\n",
    "\n",
    "        # Couches linéaires pour Q, K, V et la sortie\n",
    "        self.qkv_proj = nn.Linear(config.d_model, 3 * config.d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(config.d_model, config.d_model, bias=False)\n",
    "\n",
    "        # RoPE (sera initialisé avec la bonne longueur de séquence plus tard si nécessaire)\n",
    "        # Note: RoPE est souvent appliqué après la projection QKV et le reshape des têtes\n",
    "        # Nous allons instancier RoPE ici mais l'appliquer dans le forward\n",
    "        self.rope = RotaryPositionalEmbedding(\n",
    "            dim=self.head_dim,\n",
    "            seq_len=config.block_size, # Longueur max\n",
    "            theta=config.rope_theta,\n",
    "            device=config.device\n",
    "        )\n",
    "\n",
    "        # Masque causal précalculé (pour ne pas le recréer à chaque fois)\n",
    "        # Shape: (1, 1, block_size, block_size)\n",
    "        self.register_buffer(\"causal_mask\", torch.tril(torch.ones(config.block_size, config.block_size, dtype=torch.bool)).view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        B, T, C = x.shape # Batch, Sequence Length, Embedding Dim (d_model)\n",
    "\n",
    "        # 1. Projections Q, K, V\n",
    "        qkv = self.qkv_proj(x) # (B, T, 3*C)\n",
    "\n",
    "        # 2. Séparer Q, K, V et les têtes\n",
    "        # (B, T, 3*C) -> (B, T, 3, H, Dk) -> 3 x (B, T, H, Dk)\n",
    "        qkv = qkv.view(B, T, 3, self.n_heads, self.head_dim)\n",
    "        q, k, v = qkv.chunk(3, dim=2) # Sépare sur la dimension 3 (qui a taille 3)\n",
    "        q = q.squeeze(2) # (B, T, H, Dk)\n",
    "        k = k.squeeze(2) # (B, T, H, Dk)\n",
    "        v = v.squeeze(2) # (B, T, H, Dk)\n",
    "\n",
    "        # 3. Appliquer RoPE\n",
    "        q_rope, k_rope = self.rope(q, k) # Applique RoPE sur (B, T, H, Dk)\n",
    "\n",
    "        # 4. Transposer pour le calcul de l'attention: (B, H, T, Dk)\n",
    "        q_rope = q_rope.transpose(1, 2)\n",
    "        k_rope = k_rope.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # 5. Calcul des scores d'attention (Scaled Dot-Product)\n",
    "        # (B, H, T, Dk) @ (B, H, Dk, T) -> (B, H, T, T)\n",
    "        scores = (q_rope @ k_rope.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
    "\n",
    "        # 6. Appliquer le masque causal\n",
    "        # Le masque causal a shape (1, 1, T_max, T_max)\n",
    "        # On prend la partie correspondante à la longueur T actuelle\n",
    "        mask = self.causal_mask[:, :, :T, :T]\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # 7. Appliquer Softmax\n",
    "        attn_weights = F.softmax(scores, dim=-1) # (B, H, T, T)\n",
    "        # Gérer les NaN potentiels (si une ligne est entièrement -inf)\n",
    "        attn_weights = torch.nan_to_num(attn_weights)\n",
    "\n",
    "        # 8. Appliquer les poids d'attention à V\n",
    "        # (B, H, T, T) @ (B, H, T, Dk) -> (B, H, T, Dk)\n",
    "        attn_output = attn_weights @ v\n",
    "\n",
    "        # 9. Concaténer les têtes\n",
    "        # (B, H, T, Dk) -> (B, T, H, Dk) -> (B, T, C)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        # 10. Projection de sortie\n",
    "        output = self.o_proj(attn_output)\n",
    "        return output\n",
    "\n",
    "class ExpertMLP(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        hidden_dim = config.intermediate_size_expert\n",
    "        # Combine les projections Gate et Up pour l'efficacité (comme dans Llama)\n",
    "        self.gate_up_proj = nn.Linear(config.d_model, 2 * hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, config.d_model, bias=False)\n",
    "        self.act_fn = nn.SiLU() # SwiGLU implicite\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (..., d_model)\n",
    "        gate_up = self.gate_up_proj(x) # (..., 2 * hidden_dim)\n",
    "        gate, up = gate_up.chunk(2, dim=-1) # (..., hidden_dim)\n",
    "        fused_activation = self.act_fn(gate) * up # (..., hidden_dim)\n",
    "        output = self.down_proj(fused_activation) # (..., d_model)\n",
    "        return output\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.num_experts = config.num_local_experts\n",
    "        self.num_experts_per_tok = config.num_experts_per_tok\n",
    "        self.d_model = config.d_model\n",
    "\n",
    "        # La couche de routage (gate)\n",
    "        self.gate = nn.Linear(config.d_model, self.num_experts, bias=False)\n",
    "\n",
    "        # Les experts eux-mêmes\n",
    "        self.experts = nn.ModuleList([ExpertMLP(config) for _ in range(self.num_experts)])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        B, T, C = x.shape # Batch, Sequence Length, Dim\n",
    "\n",
    "        # 1. Obtenir les logits du routeur\n",
    "        # x: (B, T, C) -> router_logits: (B, T, num_experts)\n",
    "        router_logits = self.gate(x)\n",
    "\n",
    "        # 2. Sélectionner les Top-K experts et calculer les poids de routage\n",
    "        # routing_weights: (B, T, k), selected_experts: (B, T, k)\n",
    "        routing_weights, selected_experts = torch.topk(\n",
    "            router_logits, self.num_experts_per_tok, dim=-1\n",
    "        )\n",
    "        # Appliquer Softmax (ou Sigmoid comme dans le code original) sur les poids des k experts sélectionnés\n",
    "        # Le code original utilise Sigmoid, ce qui ne garantit pas que la somme soit 1.\n",
    "        # Softmax semble plus standard pour pondérer les sorties. Utilisons Softmax ici.\n",
    "        routing_weights = F.softmax(routing_weights, dim=-1, dtype=torch.float).to(x.dtype)\n",
    "        # Si on veut Sigmoid comme l'original:\n",
    "        # routing_weights = torch.sigmoid(routing_weights)\n",
    "\n",
    "        # 3. Préparer pour le calcul parallèle des experts\n",
    "        # Aplatir B et T pour traiter chaque token indépendamment\n",
    "        x_flat = x.view(-1, C) # (B*T, C)\n",
    "        routing_weights_flat = routing_weights.view(-1, self.num_experts_per_tok) # (B*T, k)\n",
    "        selected_experts_flat = selected_experts.view(-1, self.num_experts_per_tok) # (B*T, k)\n",
    "\n",
    "        # Initialiser le tenseur de sortie final (même taille que x_flat)\n",
    "        final_output_flat = torch.zeros_like(x_flat)\n",
    "\n",
    "        # Obtenir les indices des tokens (0 à B*T - 1)\n",
    "        token_indices = torch.arange(B * T, device=x.device)\n",
    "\n",
    "        # 4. Itérer sur les experts et calculer les sorties\n",
    "        # C'est l'approche la plus simple, mais peut être inefficace.\n",
    "        # L'approche du code original avec scatter_add est plus performante.\n",
    "        # Répliquons l'approche scatter_add :\n",
    "\n",
    "        # Créer un index plat pour les tokens et les experts sélectionnés\n",
    "        # token_idx_expanded: (B*T*k) - Répète chaque index de token k fois\n",
    "        token_idx_expanded = token_indices.repeat_interleave(self.num_experts_per_tok)\n",
    "        # expert_idx_flat: (B*T*k) - Les indices des experts sélectionnés pour chaque token*expert\n",
    "        expert_idx_flat = selected_experts_flat.view(-1)\n",
    "        # routing_weights_flat_expanded: (B*T*k) - Les poids associés\n",
    "        routing_weights_flat_expanded = routing_weights_flat.view(-1)\n",
    "\n",
    "        # Créer un batch pour chaque expert\n",
    "        # expert_inputs: (B*T*k, C) - Les inputs x_flat dupliqués pour chaque expert sélectionné\n",
    "        expert_inputs = x_flat[token_idx_expanded]\n",
    "\n",
    "        # Calculer les sorties des experts de manière batchée (si possible, sinon itérer)\n",
    "        # Ici, nous allons utiliser une boucle pour la clarté, mais une implémentation\n",
    "        # optimisée utiliserait des opérations batchées ou scatter/gather.\n",
    "        expert_outputs_list = []\n",
    "        for i in range(self.num_experts):\n",
    "            # Trouver les indices des tokens qui ont sélectionné cet expert\n",
    "            mask = (expert_idx_flat == i)\n",
    "            if mask.any():\n",
    "                # Sélectionner les inputs et les poids pour cet expert\n",
    "                current_inputs = expert_inputs[mask] # (N_i, C) où N_i est le nb de tokens routés vers l'expert i\n",
    "                # Calculer la sortie de l'expert\n",
    "                current_outputs = self.experts[i](current_inputs) # (N_i, C)\n",
    "                # Pondérer par les poids de routage correspondants\n",
    "                current_weights = routing_weights_flat_expanded[mask].unsqueeze(1) # (N_i, 1)\n",
    "                weighted_outputs = current_outputs * current_weights # (N_i, C)\n",
    "\n",
    "                # Utiliser scatter_add_ pour ajouter les sorties pondérées aux bonnes positions\n",
    "                # Indices originaux des tokens qui ont utilisé cet expert\n",
    "                original_token_indices = token_idx_expanded[mask]\n",
    "                final_output_flat.scatter_add_(0, original_token_indices.unsqueeze(1).expand(-1, C), weighted_outputs)\n",
    "\n",
    "        # 5. Remettre en forme la sortie\n",
    "        # final_output_flat: (B*T, C) -> (B, T, C)\n",
    "        final_output = final_output_flat.view(B, T, C)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "class SharedMLP(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        hidden_dim = config.intermediate_size_shared\n",
    "        # Structure similaire à ExpertMLP mais avec des dimensions potentiellement différentes\n",
    "        self.gate_proj = nn.Linear(config.d_model, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(config.d_model, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, config.d_model, bias=False)\n",
    "        self.act_fn = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate = self.gate_proj(x)\n",
    "        up = self.up_proj(x)\n",
    "        fused_activation = self.act_fn(gate) * up\n",
    "        output = self.down_proj(fused_activation)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.n_heads = config.n_heads\n",
    "        self.d_model = config.d_model\n",
    "\n",
    "        # Normalisation avant l'attention\n",
    "        self.input_layernorm = RMSNorm(config.d_model, eps=config.rms_norm_eps)\n",
    "        # Module d'attention\n",
    "        self.self_attn = Attention(config)\n",
    "        # Normalisation avant le MoE/MLP\n",
    "        self.post_attention_layernorm = RMSNorm(config.d_model, eps=config.rms_norm_eps)\n",
    "        # Mixture of Experts\n",
    "        self.moe = MoE(config)\n",
    "        # MLP Partagé\n",
    "        self.shared_mlp = SharedMLP(config)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Connexion résiduelle 1 (autour de l'attention)\n",
    "        residual = x\n",
    "        h = self.input_layernorm(x)\n",
    "        attn_output = self.self_attn(h)\n",
    "        h = residual + attn_output\n",
    "\n",
    "        # Connexion résiduelle 2 (autour du MoE et MLP partagé)\n",
    "        residual = h\n",
    "        h_norm = self.post_attention_layernorm(h)\n",
    "        # Calculer les sorties du MoE et du MLP partagé\n",
    "        moe_output = self.moe(h_norm)\n",
    "        shared_output = self.shared_mlp(h_norm)\n",
    "        # Combiner les sorties (addition simple comme dans le papier Llama 3/4)\n",
    "        h = residual + moe_output + shared_output\n",
    "\n",
    "        return h\n",
    "\n",
    "# --- Modèle Llama Complet ---\n",
    "\n",
    "class LlamaMoEModel(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Embedding des tokens\n",
    "        self.tok_embeddings = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        # Blocs Transformer\n",
    "        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
    "\n",
    "        # Normalisation finale\n",
    "        self.norm = RMSNorm(config.d_model, eps=config.rms_norm_eps)\n",
    "\n",
    "        # Tête de classification (prédit le prochain token)\n",
    "        # Note: Parfois, les poids de l'embedding sont liés (partagés) avec cette couche\n",
    "        self.output = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "\n",
    "        # Initialisation des poids (optionnel mais recommandé)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Initialisation standard pour les transformeurs\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        B, T = tokens.shape\n",
    "        # 1. Obtenir les embeddings des tokens\n",
    "        h = self.tok_embeddings(tokens) # (B, T, C)\n",
    "\n",
    "        # 2. Passer à travers les blocs Transformer\n",
    "        for layer in self.layers:\n",
    "            h = layer(h)\n",
    "\n",
    "        # 3. Normalisation finale\n",
    "        h = self.norm(h)\n",
    "\n",
    "        # 4. Calculer les logits de sortie\n",
    "        logits = self.output(h) # (B, T, VocabSize)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def generate(self, tokenizer, prompt: str, max_new_tokens: int, block_size: int, device: str):\n",
    "        self.eval() # Mettre le modèle en mode évaluation\n",
    "        # Encoder l'amorce\n",
    "        prompt_ids = tokenizer.encode(prompt)\n",
    "        context = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "\n",
    "        generated_ids = []\n",
    "\n",
    "        print(f\"Génération à partir de : '{prompt}'\")\n",
    "        with torch.no_grad(): # Pas besoin de calculer les gradients\n",
    "            for _ in range(max_new_tokens):\n",
    "                # S'assurer que le contexte ne dépasse pas block_size\n",
    "                context_cond = context[:, -block_size:]\n",
    "                # Obtenir les logits du modèle\n",
    "                logits = self(context_cond) # (B, T, VocabSize)\n",
    "                # Prendre les logits du dernier token seulement\n",
    "                logits_last = logits[:, -1, :] # (B, VocabSize)\n",
    "                # Appliquer softmax pour obtenir les probabilités\n",
    "                probs = F.softmax(logits_last, dim=-1) # (B, VocabSize)\n",
    "                # Échantillonner le prochain token basé sur les probabilités\n",
    "                next_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "                # Ajouter le token généré à la séquence\n",
    "                context = torch.cat((context, next_token), dim=1)\n",
    "                generated_ids.append(next_token.item())\n",
    "                # Afficher le caractère généré (optionnel)\n",
    "                # print(tokenizer.decode([next_token.item()]), end='', flush=True)\n",
    "\n",
    "\n",
    "        print(\"\\n--- Génération terminée ---\")\n",
    "        self.train() # Remettre en mode entraînement par défaut\n",
    "        return tokenizer.decode(prompt_ids + generated_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonctions d'Entraînement et de Sauvegarde ---\n",
    "def train_model(model, train_x, train_y, attention_mask, config, optimizer, criterion):\n",
    "\n",
    "    print(f\"\\n--- Démarrage de l'entraînement pour {config.epochs} époques ---\")\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        xb, yb, attention_mask_batch = get_batch(train_x, train_y, attention_mask, config.batch_size, config.device)\n",
    "        logits = model(xb)\n",
    "\n",
    "        B_loss, T_loss, V_loss = logits.shape\n",
    "        logits_for_loss = logits.view(B_loss * T_loss, V_loss)\n",
    "        targets_for_loss = yb.view(B_loss * T_loss)\n",
    "        # Appliquer le masque d'attention pour ne considérer que les tokens non-padding dans le calcul de la perte.\n",
    "        loss = criterion(logits_for_loss, targets_for_loss)\n",
    "        loss = (loss * attention_mask_batch.view(-1)).sum() / attention_mask_batch.sum() #IMPORTANT\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        losses.append(current_loss)\n",
    "        if epoch % config.eval_interval == 0 or epoch == config.epochs - 1:\n",
    "            print(f\"  Époque {epoch+1}/{config.epochs}, Perte: {current_loss:.4f}\")\n",
    "\n",
    "    print(\"--- Entraînement terminé ---\")\n",
    "\n",
    "    # Afficher le graphique des pertes\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"Perte d'entraînement au fil des époques\")\n",
    "        plt.xlabel(\"Époque\")\n",
    "        plt.ylabel(\"Perte\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"Matplotlib non trouvé, graphique des pertes ignoré.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Impossible d'afficher le graphique des pertes: {e}\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def save_model_checkpoint(model, tokenizer, config, optimizer, file_path='llama_moe_model_checkpoint.pt'):\n",
    "    \"\"\"Sauvegarde l'état du modèle, du tokenizer et de l'optimiseur.\"\"\"\n",
    "    checkpoint = {\n",
    "        'config': config.__dict__, # Sauvegarder la configuration\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'tokenizer': { # Sauvegarder les mappings du tokenizer\n",
    "            'char_to_int': tokenizer.char_to_int,\n",
    "            'int_to_char': tokenizer.int_to_char,\n",
    "            'chars': tokenizer.chars,\n",
    "            'vocab_size': tokenizer.vocab_size\n",
    "        }\n",
    "    }\n",
    "    # Créer le répertoire si nécessaire\n",
    "    save_dir = os.path.dirname(file_path)\n",
    "    if save_dir and not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Checkpoint du modèle sauvegardé dans '{file_path}'\")\n",
    "\n",
    "def load_model_from_checkpoint(file_path='llama_moe_model_checkpoint.pt'):\n",
    "    \"\"\"Charge un modèle à partir d'un checkpoint.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Fichier de checkpoint '{file_path}' non trouvé.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    checkpoint = torch.load(file_path, map_location=lambda storage, loc: storage) # Charger sur CPU par défaut\n",
    "\n",
    "    # Recréer la configuration\n",
    "    loaded_config_dict = checkpoint['config']\n",
    "    loaded_config = Config() # Créer une instance vide\n",
    "    # Mettre à jour avec les valeurs chargées\n",
    "    for key, value in loaded_config_dict.items():\n",
    "         if hasattr(loaded_config, key):\n",
    "              setattr(loaded_config, key, value)\n",
    "    # Recalculer les valeurs dérivées\n",
    "    loaded_config.__post_init__()\n",
    "    # Définir le device actuel\n",
    "    loaded_config.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Recréer le tokenizer\n",
    "    tokenizer_data = checkpoint['tokenizer']\n",
    "    tokenizer = SimpleCharTokenizer(\"\") # Initialiser avec un corpus vide\n",
    "    tokenizer.char_to_int = tokenizer_data['char_to_int']\n",
    "    tokenizer.int_to_char = tokenizer_data['int_to_char']\n",
    "    tokenizer.chars = tokenizer_data['chars']\n",
    "    tokenizer.vocab_size = tokenizer_data['vocab_size']\n",
    "    # Mettre à jour la taille du vocabulaire dans la config chargée\n",
    "    loaded_config.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "    # Recréer le modèle\n",
    "    model = LlamaMoEModel(loaded_config)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(loaded_config.device) # Déplacer vers le bon device\n",
    "\n",
    "    # Recréer l'optimiseur (optionnel, utile si on reprend l'entraînement)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=loaded_config.learning_rate)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    print(f\"Modèle chargé depuis '{file_path}' sur le device '{loaded_config.device}'\")\n",
    "    return model, tokenizer, loaded_config, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T08:58:22.308363Z",
     "iopub.status.busy": "2025-05-07T08:58:22.308065Z",
     "iopub.status.idle": "2025-05-07T09:07:29.151992Z",
     "shell.execute_reply": "2025-05-07T09:07:29.151197Z",
     "shell.execute_reply.started": "2025-05-07T08:58:22.308340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device: cuda\n",
      "--- Configuration du Modèle ---\n",
      "d_k: 64\n",
      "intermediate_size_expert: 512\n",
      "intermediate_size_shared: 512\n",
      "-----------------------------\n",
      "Chargement des données...\n",
      "Corpus brut chargé (longueur: 147641326 caractères).\n",
      "Tokenizer créé avec une taille de vocabulaire de: 1787\n",
      "727086 paires de séquences input/target créées.\n",
      "Shape de train_x: torch.Size([727086, 512])\n",
      "Shape de train_y: torch.Size([727086, 512])\n",
      "Shape de attention_mask: torch.Size([727086, 512])\n",
      "\n",
      "Modèle initialisé sur cuda\n",
      "Nombre total de paramètres entraînables: 9,834,240\n",
      "Optimiseur: AdamW, Fonction de perte: CrossEntropyLoss\n",
      "\n",
      "--- Démarrage de l'entraînement pour 12000 époques ---\n",
      "  Époque 1/12000, Perte: 7.5616\n",
      "  Époque 301/12000, Perte: 2.2396\n",
      "  Époque 601/12000, Perte: 1.8567\n",
      "  Époque 901/12000, Perte: 1.5500\n",
      "  Époque 1201/12000, Perte: 1.7405\n",
      "  Époque 1501/12000, Perte: 1.5614\n",
      "  Époque 1801/12000, Perte: 1.3123\n",
      "  Époque 2101/12000, Perte: 1.5364\n",
      "  Époque 2401/12000, Perte: 1.4552\n",
      "  Époque 2701/12000, Perte: 1.3997\n",
      "  Époque 3001/12000, Perte: 1.3626\n",
      "  Époque 3301/12000, Perte: 1.2398\n",
      "  Époque 3601/12000, Perte: 1.5468\n",
      "  Époque 3901/12000, Perte: 1.5149\n",
      "  Époque 4201/12000, Perte: 1.3913\n",
      "  Époque 4501/12000, Perte: 1.2446\n",
      "  Époque 4801/12000, Perte: 1.0682\n",
      "  Époque 5101/12000, Perte: 1.0339\n",
      "  Époque 5401/12000, Perte: 1.3177\n",
      "  Époque 5701/12000, Perte: 1.0389\n",
      "  Époque 6001/12000, Perte: 1.2234\n",
      "  Époque 6301/12000, Perte: 1.4454\n",
      "  Époque 6601/12000, Perte: 1.2076\n",
      "  Époque 6901/12000, Perte: 0.9197\n",
      "  Époque 7201/12000, Perte: 1.2053\n",
      "  Époque 7501/12000, Perte: 1.1672\n",
      "  Époque 7801/12000, Perte: 1.1499\n",
      "  Époque 8101/12000, Perte: 0.9868\n",
      "  Époque 8401/12000, Perte: 1.0673\n",
      "  Époque 8701/12000, Perte: 1.1009\n",
      "  Époque 9001/12000, Perte: 1.0214\n",
      "  Époque 9301/12000, Perte: 1.2322\n",
      "  Époque 9601/12000, Perte: 0.9581\n",
      "  Époque 9901/12000, Perte: 1.0002\n",
      "  Époque 10201/12000, Perte: 0.9888\n",
      "  Époque 10501/12000, Perte: 1.3238\n",
      "  Époque 10801/12000, Perte: 0.8220\n",
      "  Époque 11101/12000, Perte: 0.8718\n",
      "  Époque 11401/12000, Perte: 0.9772\n",
      "  Époque 11701/12000, Perte: 0.9174\n",
      "  Époque 12000/12000, Perte: 0.8265\n",
      "--- Entraînement terminé ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération de Texte ---\n",
      "Génération à partir de : 'Le service '\n",
      "\n",
      "--- Génération terminée ---\n",
      "\n",
      "Texte Généré:\n",
      "Le service obtient devint tant dans l'installation de mixer la chanson. Le tribunal special continue egalement Anne. Soleure prend situe respectoire de techniques connaissant le Grand ou Saint-Gall jusqu'a mais \n",
      "\n",
      "--- Sauvegarde du Modèle ---\n",
      "Checkpoint du modèle sauvegardé dans 'saved_models_restructured/llama_moe_model_final.pt'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"Utilisation du device: {config.device}\")\n",
    "    config.print_config()\n",
    "\n",
    "    # 1. Charger et préparer les données\n",
    "    try:\n",
    "        train_x, train_y, attention_mask, tokenizer = load_and_prepare_data(config)\n",
    "    except ValueError as e:\n",
    "        print(f\"Erreur lors de la préparation des données: {e}\")\n",
    "        exit() # Arrêter si les données ne peuvent pas être préparées\n",
    "\n",
    "    # Mettre à jour la config avec la taille réelle du vocabulaire\n",
    "    if config.vocab_size is None:\n",
    "         config.vocab_size = tokenizer.vocab_size\n",
    "         print(f\"Taille du vocabulaire mise à jour dans la config: {config.vocab_size}\")\n",
    "\n",
    "\n",
    "    # 2. Initialiser le modèle\n",
    "    model = LlamaMoEModel(config).to(config.device)\n",
    "    print(f\"\\nModèle initialisé sur {config.device}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Nombre total de paramètres entraînables: {total_params:,}\")\n",
    "\n",
    "    # 3. Définir l'optimiseur et la fonction de perte\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(f\"Optimiseur: {type(optimizer).__name__}, Fonction de perte: {type(criterion).__name__}\")\n",
    "\n",
    "    # 4. Entraîner le modèle\n",
    "    train_model(model, train_x, train_y, attention_mask, config, optimizer, criterion)\n",
    "\n",
    "    # 5. Générer du texte\n",
    "    print(\"\\n--- Génération de Texte ---\")\n",
    "    prompt = \"Le service \"\n",
    "    generated_text = model.generate(\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        max_new_tokens=200,\n",
    "        block_size=config.block_size,\n",
    "        device=config.device\n",
    "    )\n",
    "    print(\"\\nTexte Généré:\")\n",
    "    print(generated_text)\n",
    "\n",
    "    # 6. Sauvegarder le modèle\n",
    "    print(\"\\n--- Sauvegarde du Modèle ---\")\n",
    "    save_dir = 'saved_models_restructured'\n",
    "    save_path = os.path.join(save_dir, 'llama_moe_model_final.pt')\n",
    "    save_model_checkpoint(model, tokenizer, config, optimizer, file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:07:29.153884Z",
     "iopub.status.busy": "2025-05-07T09:07:29.153259Z",
     "iopub.status.idle": "2025-05-07T09:07:29.967692Z",
     "shell.execute_reply": "2025-05-07T09:07:29.967052Z",
     "shell.execute_reply.started": "2025-05-07T09:07:29.153862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test du Chargement du Modèle ---\n",
      "Tokenizer créé avec une taille de vocabulaire de: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2988435836.py:651: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path, map_location=lambda storage, loc: storage) # Charger sur CPU par défaut\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé depuis 'saved_models_restructured/llama_moe_model_final.pt' sur le device 'cuda'\n",
      "Modèle chargé avec succès. Nouvelle génération de test:\n",
      "Génération à partir de : 'Bonjour '\n",
      "\n",
      "--- Génération terminée ---\n",
      "\n",
      "Texte Généré (après chargement):\n",
      "Bonjour role en 1493 et elle n'etait pas de faible indusgr\n",
      "\n",
      "--- Script Terminé ---\n"
     ]
    }
   ],
   "source": [
    "# 7. Charger et tester le modèle sauvegardé\n",
    "print(\"\\n--- Test du Chargement du Modèle ---\")\n",
    "loaded_model, loaded_tokenizer, loaded_config, _ = load_model_from_checkpoint(file_path=save_path)\n",
    "\n",
    "if loaded_model and loaded_tokenizer:\n",
    "    print(\"Modèle chargé avec succès. Nouvelle génération de test:\")\n",
    "    test_prompt = \"Longtemps je me suis couché de bonne heure.\"\n",
    "    test_generated_text = loaded_model.generate(\n",
    "        tokenizer=loaded_tokenizer,\n",
    "        prompt=test_prompt,\n",
    "        max_new_tokens=50,\n",
    "        block_size=loaded_config.block_size, # Utiliser la config chargée\n",
    "        device=loaded_config.device\n",
    "    )\n",
    "    print(\"\\nTexte Généré (après chargement):\")\n",
    "    print(test_generated_text)\n",
    "else:\n",
    "    print(\"Échec du chargement du modèle.\")\n",
    "    \n",
    "print(\"\\n--- Script Terminé ---\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
